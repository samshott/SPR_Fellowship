{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first we import all the neccessary packages for working with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import display\n",
    "#import hoboreader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import matplotlib as mp\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next we ensure that our working directory is set correctly so that when we're working with file paths they always work relative to our project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\samer\\\\OneDrive - Cal Poly\\\\Classes\\\\SPR_Fellowship\\\\SPR_Fellowship'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#os.chdir(\"..\")\n",
    "os.chdir(\"C:\\\\Users\\\\samer\\\\OneDrive - Cal Poly\\\\Classes\\\\SPR_Fellowship\\\\SPR_Fellowship\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First well create a function for searching through complex fill structures and returning the paths to files of only a certain file type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_filetype(path = \".\", extentension = \"\"):\n",
    "    \"\"\"\n",
    "    :param path: string, where to search\n",
    "    :param extentension: string, what files to look for\n",
    "    :return: list, paths to all files with a matching extension\n",
    "    \"\"\"\n",
    "    paths = []\n",
    "    for dirpath, dirnames, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            if filename[-len(extentension):] == extentension:\n",
    "                paths.append(dirpath + \"/\" + filename)\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well also want some test data to work with along the way before we start working with thousands of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LegacyFiles/All_txt/txt_header_examples//Al RRG_030916.txt', 'LegacyFiles/All_txt/txt_header_examples//AL RRG_060403a.txt', 'LegacyFiles/All_txt/txt_header_examples//AL_RRG_091222 remove first tip.txt']\n"
     ]
    }
   ],
   "source": [
    "list_ex_headers = search_filetype(path=\"LegacyFiles/All_txt/txt_header_examples/\", extentension=\".txt\")\n",
    "\n",
    "print(list_ex_headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Headers\n",
    "Next we create a function for working with the messsy headers created by the text files.  There are a few different ones to worry about, we have to manage for each one, while preserving inprotant information, like file name and serial numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def header_fixer(path = \".\"):\n",
    "    \"\"\"\n",
    "    :param path: path to the txt/csv file\n",
    "    :return: a dataframe with a fixed header\n",
    "    \"\"\"\n",
    "    csv = pd.read_csv(path, sep=\"\\t\") #read in the csv just to check its structure\n",
    "    \n",
    "    if csv.shape[1] < 2:  #because files with SN have a multiline header this will filter those files out\n",
    "        serial_Num = re.findall(\"[0-9]{5,6}\", csv.columns[0])\n",
    "        csv = pd.read_csv(path, header=1, sep=\"\\t\")\n",
    "        csv[\"Serial Number\"] = serial_Num[0]\n",
    "    else:\n",
    "        csv = pd.read_csv(path, sep=\"\\t\")\n",
    "        csv[\"Serial Number\"] =  None\n",
    "\n",
    "    return csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "great, now lets test it out on our small sample of txt files we created before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Time</th>\n",
       "      <th>Event (Rain Bucket Tip)</th>\n",
       "      <th>Serial Number</th>\n",
       "      <th>FileName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06/18/03 08:40:17.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>Al RRG_030916.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09/09/03 14:19:42.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>Al RRG_030916.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09/09/03 15:43:36.5</td>\n",
       "      <td>0.02</td>\n",
       "      <td>None</td>\n",
       "      <td>Al RRG_030916.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>09/09/03 16:33:22.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>None</td>\n",
       "      <td>Al RRG_030916.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09/09/03 17:20:45.5</td>\n",
       "      <td>0.04</td>\n",
       "      <td>None</td>\n",
       "      <td>Al RRG_030916.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date Time  Event (Rain Bucket Tip) Serial Number  \\\n",
       "0  06/18/03 08:40:17.0                     0.00          None   \n",
       "1  09/09/03 14:19:42.0                     0.01          None   \n",
       "2  09/09/03 15:43:36.5                     0.02          None   \n",
       "3  09/09/03 16:33:22.0                     0.03          None   \n",
       "4  09/09/03 17:20:45.5                     0.04          None   \n",
       "\n",
       "            FileName  \n",
       "0  Al RRG_030916.txt  \n",
       "1  Al RRG_030916.txt  \n",
       "2  Al RRG_030916.txt  \n",
       "3  Al RRG_030916.txt  \n",
       "4  Al RRG_030916.txt  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Time</th>\n",
       "      <th>Event (Rain bucket tip)</th>\n",
       "      <th>Serial Number</th>\n",
       "      <th>FileName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03/26/06 17:58:38.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>531980</td>\n",
       "      <td>AL RRG_060403a.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03/27/06 13:23:29.5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>531980</td>\n",
       "      <td>AL RRG_060403a.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03/27/06 13:37:13.5</td>\n",
       "      <td>0.02</td>\n",
       "      <td>531980</td>\n",
       "      <td>AL RRG_060403a.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03/27/06 13:47:53.5</td>\n",
       "      <td>0.03</td>\n",
       "      <td>531980</td>\n",
       "      <td>AL RRG_060403a.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03/27/06 13:53:57.5</td>\n",
       "      <td>0.04</td>\n",
       "      <td>531980</td>\n",
       "      <td>AL RRG_060403a.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date Time  Event (Rain bucket tip) Serial Number  \\\n",
       "0  03/26/06 17:58:38.0                     0.00        531980   \n",
       "1  03/27/06 13:23:29.5                     0.01        531980   \n",
       "2  03/27/06 13:37:13.5                     0.02        531980   \n",
       "3  03/27/06 13:47:53.5                     0.03        531980   \n",
       "4  03/27/06 13:53:57.5                     0.04        531980   \n",
       "\n",
       "             FileName  \n",
       "0  AL RRG_060403a.txt  \n",
       "1  AL RRG_060403a.txt  \n",
       "2  AL RRG_060403a.txt  \n",
       "3  AL RRG_060403a.txt  \n",
       "4  AL RRG_060403a.txt  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Time</th>\n",
       "      <th>Event (Events)</th>\n",
       "      <th>Serial Number</th>\n",
       "      <th>FileName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12/15/09 16:31:03.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>AL_RRG_091222 remove first tip.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/15/09 16:31:24.0</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>None</td>\n",
       "      <td>AL_RRG_091222 remove first tip.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/16/09 09:04:57.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>None</td>\n",
       "      <td>AL_RRG_091222 remove first tip.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/16/09 09:20:12.5</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>None</td>\n",
       "      <td>AL_RRG_091222 remove first tip.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/16/09 09:40:41.0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>None</td>\n",
       "      <td>AL_RRG_091222 remove first tip.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date Time  Event (Events) Serial Number  \\\n",
       "0  12/15/09 16:31:03.0        0.000000          None   \n",
       "1  12/15/09 16:31:24.0        0.010870          None   \n",
       "2  12/16/09 09:04:57.0        0.021739          None   \n",
       "3  12/16/09 09:20:12.5        0.032609          None   \n",
       "4  12/16/09 09:40:41.0        0.043478          None   \n",
       "\n",
       "                             FileName  \n",
       "0  AL_RRG_091222 remove first tip.txt  \n",
       "1  AL_RRG_091222 remove first tip.txt  \n",
       "2  AL_RRG_091222 remove first tip.txt  \n",
       "3  AL_RRG_091222 remove first tip.txt  \n",
       "4  AL_RRG_091222 remove first tip.txt  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "ex_headers_csv_list = []\n",
    "\n",
    "for path in list_ex_headers:\n",
    "    csv = header_fixer(path = path)\n",
    "    csv[\"FileName\"] = path.split(sep=\"/\")[-1]\n",
    "    ex_headers_csv_list.append(csv) #create a list of test dataframes\n",
    "    display(csv.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deal with column names\n",
    "That seems to be working okay, but there are definitely some differences in column names that are going to give us issues later, so lets create a function to deal with those. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columnNames_handler(dataframe, column_names = []):\n",
    "    \"\"\"takes in a pandas dataframe, and replaces the column names with \n",
    "    the ones provided in the column_names list.  if lengths don't match, it retains \n",
    "    names exceeding the list, or discards names from the list if there are less \n",
    "    columns than the length of the list.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pandas dataframe): a pandas dataframe with a cleaned header.\n",
    "        column_names (list, optional): list of column names (string). Defaults to [].\n",
    "    \"\"\"\n",
    "    df_num_cols = len(dataframe.columns)\n",
    "\n",
    "    if len(column_names) > df_num_cols: #if there are too many column names given\n",
    "        column_names = column_names[:(df_num_cols)] \n",
    "    elif len(column_names) < df_num_cols: #if there are too few column names given\n",
    "        column_names = column_names + dataframe.columns[len(column_names):]\n",
    "    \n",
    "    dataframe.columns = column_names\n",
    "\n",
    "    return dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and a test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['DateTime', 'BucketTip_Cumm', 'Serial Number', 'FileName'], dtype='object')\n",
      "Index(['DateTime', 'BucketTip_Cumm', 'Serial Number', 'FileName'], dtype='object')\n",
      "Index(['DateTime', 'BucketTip_Cumm', 'Serial Number', 'FileName'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "\n",
    "column_names = [\"DateTime\",\"BucketTip_Cumm\",\"Serial Number\",\"FileName\"]\n",
    "for df in ex_headers_csv_list:\n",
    "    ex_headers_csv_list[index] = columnNames_handler(dataframe=df, column_names=column_names)\n",
    "    print(df.columns)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deal with cummulative values\n",
    "As you can see, individual bucket tips were summed up progressively as more tips were recorded.  This is helpful for finding the amount of total rainfall for the length of time between log pulls from precipitation monitors, but will make no sense when combined with other datasets.  There are a couple options for dealing with this:\n",
    "\n",
    "1. just make one record for each timespan between log pulls in the final dataset\n",
    "2. solve for each individual bucket tip and make them non-cummulative \n",
    "\n",
    "option 2 will allow us to preserve the data in its most granular form, so that future analyists can aggrigate the data as they see fit, so that is what we will work towards.\n",
    "https://stackoverflow.com/questions/27581942/how-can-i-get-back-real-value-from-cumulative-sum-in-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.00\n",
       "1     0.01\n",
       "2     0.02\n",
       "3     0.03\n",
       "4     0.04\n",
       "5     0.05\n",
       "6     0.06\n",
       "7     0.07\n",
       "8     0.08\n",
       "9     0.09\n",
       "10    0.09\n",
       "Name: BucketTip_Cumm, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_headers_csv_list[0][\"BucketTip_Cumm\"] #check accumulation of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.00\n",
       "1     0.01\n",
       "2     0.01\n",
       "3     0.01\n",
       "4     0.01\n",
       "5     0.01\n",
       "6     0.01\n",
       "7     0.01\n",
       "8     0.01\n",
       "9     0.01\n",
       "10    0.00\n",
       "Name: precip_individual, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cumm_to_individual(dataframe, column_index_or_name, indiv_column_name):\n",
    "    \"\"\"given a column with cummulative values, add a column with individual non-cummulative records\n",
    "\n",
    "    Args:\n",
    "        dataframe (pandas df): _description_\n",
    "        column_index_or_name (int or str): _description_\n",
    "        column_name (str): _description_\n",
    "    \"\"\"\n",
    "    if type(column_index_or_name) == int:\n",
    "        col = dataframe.columns[column_index_or_name]\n",
    "    else:\n",
    "        col = column_index_or_name\n",
    "        if col not in dataframe.columns:\n",
    "            return dataframe #if the specified column doesnt exist, just return the dataframe\n",
    "    dataframe[indiv_column_name] = dataframe[col].diff().fillna(dataframe[col].iloc[0])\n",
    "    return dataframe\n",
    "\n",
    "cumm_to_individual(dataframe=ex_headers_csv_list[0], column_index_or_name=\"BucketTip_Cumm\", indiv_column_name=\"precip_individual\")[\"precip_individual\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looks much better, now just iterate over all the datasets to give them all that value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# list all files\n",
    "Know we need to make a list of all the files we want to try to aggregate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_filetype(path = \".\", extentension = \"\"):\n",
    "    \"\"\"\n",
    "    :param path: string, where to search\n",
    "    :param extentension: string, what files to look for\n",
    "    :return: list, paths to all files with a matching extension\n",
    "    \"\"\"\n",
    "    paths = []\n",
    "    for dirpath, dirnames, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            if filename[-len(extentension):] == extentension:\n",
    "                paths.append(dirpath + \"/\" + filename)\n",
    "    return paths\n",
    "\n",
    "#list of all text files in the legacy files directory\n",
    "list_text_paths = search_filetype(path = \"LegacyFiles/\", extentension=\".txt\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put it all together\n",
    "Now we just iterate through all of them and see how it looks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "ticker = 0\n",
    "error_files = []\n",
    "\n",
    "for text_path in list_text_paths:\n",
    "    try:\n",
    "        #print(ticker)\n",
    "        ticker += 1\n",
    "        df = header_fixer(text_path) #read in each txt file using the header_fixer function\n",
    "        df = columnNames_handler(df, column_names=column_names)\n",
    "        df[\"FileName\"] = text_path.split(sep=\"/\")[-1]\n",
    "        df = cumm_to_individual(df, column_index_or_name=\"BucketTip_Cumm\", indiv_column_name=\"precip_individual\")\n",
    "        if len(df.columns)<=5:\n",
    "            df_list.append(df)\n",
    "    except: \n",
    "        error_files.append(text_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of total txt: 1724 \n",
      "number of error files: 86\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of total txt: {len(list_text_paths)} \\nnumber of error files: {len(error_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create a directory to save the error files, but 86 out of 1724 isnt too bad. After we run through the all the .csv files then we can get on directory full of only files that couldn't be processed.  They may need to be looked at manually depending on the total number of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_txt_errors = os.getcwd()+\"/LegacyFiles/TxtErrorFiles/\"\n",
    "os.makedirs(dest_txt_errors)\n",
    "for error_file in error_files:\n",
    "    shutil.copy2(error_file, dest_txt_errors) #copy all error files into the new directory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we just create a full dataset of all the text files we just processed.  Here we also filter out large precip numbers that don't make sense at our known bucket tip scale of .001\", and we convert them by the scale factor to match the rest of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>BucketTip_Cumm</th>\n",
       "      <th>Serial Number</th>\n",
       "      <th>FileName</th>\n",
       "      <th>precip_individual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12/15/09 16:31:03.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>AL_RRG_091222 remove first tip.txt</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/15/09 16:31:24.0</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>None</td>\n",
       "      <td>AL_RRG_091222 remove first tip.txt</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/16/09 09:04:57.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>None</td>\n",
       "      <td>AL_RRG_091222 remove first tip.txt</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/16/09 09:20:12.5</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>None</td>\n",
       "      <td>AL_RRG_091222 remove first tip.txt</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/16/09 09:40:41.0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>None</td>\n",
       "      <td>AL_RRG_091222 remove first tip.txt</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12/16/09 10:40:35.0</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>None</td>\n",
       "      <td>AL_RRG_091222 remove first tip.txt</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12/16/09 10:57:48.0</td>\n",
       "      <td>0.065218</td>\n",
       "      <td>None</td>\n",
       "      <td>AL_RRG_091222 remove first tip.txt</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12/16/09 11:32:49.5</td>\n",
       "      <td>0.076087</td>\n",
       "      <td>None</td>\n",
       "      <td>AL_RRG_091222 remove first tip.txt</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12/16/09 12:40:00.5</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>None</td>\n",
       "      <td>AL_RRG_091222 remove first tip.txt</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12/17/09 03:26:02.5</td>\n",
       "      <td>0.097826</td>\n",
       "      <td>None</td>\n",
       "      <td>AL_RRG_091222 remove first tip.txt</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12/21/09 08:11:05.5</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>None</td>\n",
       "      <td>AL_RRG_091222 remove first tip.txt</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12/21/09 11:26:27.5</td>\n",
       "      <td>0.119566</td>\n",
       "      <td>None</td>\n",
       "      <td>AL_RRG_091222 remove first tip.txt</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12/21/09 12:05:51.0</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>None</td>\n",
       "      <td>AL_RRG_091222 remove first tip.txt</td>\n",
       "      <td>0.010869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12/21/09 12:11:00.5</td>\n",
       "      <td>0.141305</td>\n",
       "      <td>None</td>\n",
       "      <td>AL_RRG_091222 remove first tip.txt</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12/21/09 12:17:02.5</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>None</td>\n",
       "      <td>AL_RRG_091222 remove first tip.txt</td>\n",
       "      <td>0.010869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12/21/09 12:25:05.5</td>\n",
       "      <td>0.163044</td>\n",
       "      <td>None</td>\n",
       "      <td>AL_RRG_091222 remove first tip.txt</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12/21/09 12:39:22.0</td>\n",
       "      <td>0.173914</td>\n",
       "      <td>None</td>\n",
       "      <td>AL_RRG_091222 remove first tip.txt</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>12/21/09 13:07:34.5</td>\n",
       "      <td>0.184783</td>\n",
       "      <td>None</td>\n",
       "      <td>AL_RRG_091222 remove first tip.txt</td>\n",
       "      <td>0.010869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>12/21/09 13:11:35.5</td>\n",
       "      <td>0.195653</td>\n",
       "      <td>None</td>\n",
       "      <td>AL_RRG_091222 remove first tip.txt</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>12/21/09 13:15:46.5</td>\n",
       "      <td>0.206522</td>\n",
       "      <td>None</td>\n",
       "      <td>AL_RRG_091222 remove first tip.txt</td>\n",
       "      <td>0.010869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               DateTime  BucketTip_Cumm Serial Number  \\\n",
       "0   12/15/09 16:31:03.0        0.000000          None   \n",
       "1   12/15/09 16:31:24.0        0.010870          None   \n",
       "2   12/16/09 09:04:57.0        0.021739          None   \n",
       "3   12/16/09 09:20:12.5        0.032609          None   \n",
       "4   12/16/09 09:40:41.0        0.043478          None   \n",
       "5   12/16/09 10:40:35.0        0.054348          None   \n",
       "6   12/16/09 10:57:48.0        0.065218          None   \n",
       "7   12/16/09 11:32:49.5        0.076087          None   \n",
       "8   12/16/09 12:40:00.5        0.086957          None   \n",
       "9   12/17/09 03:26:02.5        0.097826          None   \n",
       "10  12/21/09 08:11:05.5        0.108696          None   \n",
       "11  12/21/09 11:26:27.5        0.119566          None   \n",
       "12  12/21/09 12:05:51.0        0.130435          None   \n",
       "13  12/21/09 12:11:00.5        0.141305          None   \n",
       "14  12/21/09 12:17:02.5        0.152174          None   \n",
       "15  12/21/09 12:25:05.5        0.163044          None   \n",
       "16  12/21/09 12:39:22.0        0.173914          None   \n",
       "17  12/21/09 13:07:34.5        0.184783          None   \n",
       "18  12/21/09 13:11:35.5        0.195653          None   \n",
       "19  12/21/09 13:15:46.5        0.206522          None   \n",
       "\n",
       "                              FileName  precip_individual  \n",
       "0   AL_RRG_091222 remove first tip.txt           0.000000  \n",
       "1   AL_RRG_091222 remove first tip.txt           0.010870  \n",
       "2   AL_RRG_091222 remove first tip.txt           0.010870  \n",
       "3   AL_RRG_091222 remove first tip.txt           0.010870  \n",
       "4   AL_RRG_091222 remove first tip.txt           0.010870  \n",
       "5   AL_RRG_091222 remove first tip.txt           0.010870  \n",
       "6   AL_RRG_091222 remove first tip.txt           0.010870  \n",
       "7   AL_RRG_091222 remove first tip.txt           0.010870  \n",
       "8   AL_RRG_091222 remove first tip.txt           0.010870  \n",
       "9   AL_RRG_091222 remove first tip.txt           0.010870  \n",
       "10  AL_RRG_091222 remove first tip.txt           0.010870  \n",
       "11  AL_RRG_091222 remove first tip.txt           0.010870  \n",
       "12  AL_RRG_091222 remove first tip.txt           0.010869  \n",
       "13  AL_RRG_091222 remove first tip.txt           0.010870  \n",
       "14  AL_RRG_091222 remove first tip.txt           0.010869  \n",
       "15  AL_RRG_091222 remove first tip.txt           0.010870  \n",
       "16  AL_RRG_091222 remove first tip.txt           0.010870  \n",
       "17  AL_RRG_091222 remove first tip.txt           0.010869  \n",
       "18  AL_RRG_091222 remove first tip.txt           0.010870  \n",
       "19  AL_RRG_091222 remove first tip.txt           0.010869  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_df = pd.concat(df_list, names=column_names, ignore_index=True)\n",
    "full_df[\"precip_individual\"] = np.where((full_df.precip_individual >= 1), full_df.precip_individual*0.001, full_df.precip_individual)\n",
    "\n",
    "display(df[0:20])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then to keep things organized we just write this intermediate file to a directory in our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_csv_write_dst = os.getcwd() + \"/csv_from_legacy/All_txt_as_csv/txts_to_csv.csv\"\n",
    "if not os.path.exists(txt_csv_write_dst): #only do this once, don't repeat on additional script runs\n",
    "    full_df.to_csv(txt_csv_write_dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## repeat for csv files from legacy exports\n",
    "now we just repeat the process for all of the .csv files exported from .hobo and .dtf files created directly by the hobo loggers. starting with .dtfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'number of .csv from .dtf: 3202'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtf_csv_file_list = search_filetype(path=\"csv_from_legacy/All_dtf_as_csv/\", extentension=\".csv\")\n",
    "f\"number of .csv from .dtf: {len(dtf_csv_file_list)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe structure from these is a bit different though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Plot Title: AL-RRG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <th>Date Time, GMT-08:00</th>\n",
       "      <td>Rain Bu (0.009999999776482582), Units (LGR S/N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>01/13/04 08:58:15 AM</th>\n",
       "      <td>28025.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>01/13/04 09:01:57.5 AM</th>\n",
       "      <td>28025.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>01/13/04 09:02:14.5 AM</th>\n",
       "      <td>28025.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>01/13/04 09:02:32 AM</th>\n",
       "      <td>28025.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <th>01/13/04 10:10:05.5 AM</th>\n",
       "      <td>28026.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <th>01/13/04 10:11:32.5 AM</th>\n",
       "      <td>28026.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <th>01/13/04 10:13:20 AM</th>\n",
       "      <td>28026.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <th>01/13/04 10:16:11 AM</th>\n",
       "      <td>28026.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <th>01/13/04 10:25:19.5 AM</th>\n",
       "      <td>28026.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          Plot Title: AL-RRG\n",
       "#  Date Time, GMT-08:00    Rain Bu (0.009999999776482582), Units (LGR S/N...\n",
       "1  01/13/04 08:58:15 AM                                             28025.11\n",
       "2  01/13/04 09:01:57.5 AM                                           28025.12\n",
       "3  01/13/04 09:02:14.5 AM                                           28025.13\n",
       "4  01/13/04 09:02:32 AM                                             28025.14\n",
       "...                                                                      ...\n",
       "94 01/13/04 10:10:05.5 AM                                           28026.04\n",
       "95 01/13/04 10:11:32.5 AM                                           28026.05\n",
       "96 01/13/04 10:13:20 AM                                             28026.06\n",
       "97 01/13/04 10:16:11 AM                                             28026.07\n",
       "98 01/13/04 10:25:19.5 AM                                           28026.07\n",
       "\n",
       "[99 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.read_csv(dtf_csv_file_list[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a couple things to note here:\n",
    " - times are listed with AM or PM at the End - we'll need to change this to international time for a standard\n",
    " - plot Title is listed in the first column, first cell - we'll want to save that to its own column\n",
    " - S/N is embeded in the second column header... what a mess...\n",
    " - Calibration for units is also embeded in the second column header... who designed this??\n",
    " - Like our previous dataset bucket tips are recorded cummulative, but here they are lifetime cummulative, this will change how we deal with it slightly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dealing with dates\n",
    "we'll start by parsing out the date, so we can convert the time to international.  We'll create a function for this since were going to have to retroactively apply this to our previous .txt dataset too so we can have a column for date, and a seperate column for time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dtf_files = dtf_csv_file_list[0:2]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "11cc95a52f21860d355b65157fedcea858f9dca3a5e33388e082c92262d6fb27"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
