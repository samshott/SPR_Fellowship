{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first we import all the neccessary packages for working with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import display\n",
    "#import hoboreader\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import matplotlib as mp\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next we ensure that our working directory is set correctly so that when we're working with file paths they always work relative to our project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\samer\\\\OneDrive - Cal Poly\\\\Classes\\\\SPR_Fellowship\\\\SPR_Fellowship'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#os.chdir(\"..\")\n",
    "os.chdir(\"C:\\\\Users\\\\samer\\\\OneDrive - Cal Poly\\\\Classes\\\\SPR_Fellowship\\\\SPR_Fellowship\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First well create a function for searching through complex fill structures and returning the paths to files of only a certain file type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_filetype(path = \".\", extentension = \"\"):\n",
    "    \"\"\"\n",
    "    :param path: string, where to search\n",
    "    :param extentension: string, what files to look for\n",
    "    :return: list, paths to all files with a matching extension\n",
    "    \"\"\"\n",
    "    paths = []\n",
    "    for dirpath, dirnames, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            if filename[-len(extentension):] == extentension:\n",
    "                paths.append(dirpath + \"/\" + filename)\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well also want some test data to work with along the way before we start working with thousands of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LegacyFiles/All_txt/txt_header_examples//Al RRG_030916.txt', 'LegacyFiles/All_txt/txt_header_examples//AL RRG_060403a.txt', 'LegacyFiles/All_txt/txt_header_examples//AL_RRG_091222 remove first tip.txt']\n"
     ]
    }
   ],
   "source": [
    "list_ex_headers = search_filetype(path=\"LegacyFiles/All_txt/txt_header_examples/\", extentension=\".txt\")\n",
    "\n",
    "print(list_ex_headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Headers\n",
    "Next we create a function for working with the messsy headers created by the text files.  There are a few different ones to worry about, we have to manage for each one, while preserving inprotant information, like file name and serial numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def header_fixer(path = \".\"):\n",
    "    \"\"\"\n",
    "    :param path: path to the txt/csv file\n",
    "    :return: a dataframe with a fixed header\n",
    "    \"\"\"\n",
    "    csv = pd.read_csv(path, sep=\"\\t\") #read in the csv just to check its structure\n",
    "    \n",
    "    if csv.shape[1] < 2:  #because files with SN have a multiline header this will filter those files out\n",
    "        serial_Num = re.findall(\"[0-9]{5,6}\", csv.columns[0])\n",
    "        csv = pd.read_csv(path, header=1, sep=\"\\t\")\n",
    "        csv[\"Serial Number\"] = serial_Num[0]\n",
    "    else:\n",
    "        csv = pd.read_csv(path, sep=\"\\t\")\n",
    "        csv[\"Serial Number\"] =  None\n",
    "\n",
    "    return csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "great, now lets test it out on our small sample of txt files we created before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Time</th>\n",
       "      <th>Event (Rain Bucket Tip)</th>\n",
       "      <th>Serial Number</th>\n",
       "      <th>FileName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06/18/03 08:40:17.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>Al RRG_030916.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09/09/03 14:19:42.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>Al RRG_030916.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09/09/03 15:43:36.5</td>\n",
       "      <td>0.02</td>\n",
       "      <td>None</td>\n",
       "      <td>Al RRG_030916.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>09/09/03 16:33:22.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>None</td>\n",
       "      <td>Al RRG_030916.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09/09/03 17:20:45.5</td>\n",
       "      <td>0.04</td>\n",
       "      <td>None</td>\n",
       "      <td>Al RRG_030916.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date Time  Event (Rain Bucket Tip) Serial Number  \\\n",
       "0  06/18/03 08:40:17.0                     0.00          None   \n",
       "1  09/09/03 14:19:42.0                     0.01          None   \n",
       "2  09/09/03 15:43:36.5                     0.02          None   \n",
       "3  09/09/03 16:33:22.0                     0.03          None   \n",
       "4  09/09/03 17:20:45.5                     0.04          None   \n",
       "\n",
       "            FileName  \n",
       "0  Al RRG_030916.txt  \n",
       "1  Al RRG_030916.txt  \n",
       "2  Al RRG_030916.txt  \n",
       "3  Al RRG_030916.txt  \n",
       "4  Al RRG_030916.txt  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Time</th>\n",
       "      <th>Event (Rain bucket tip)</th>\n",
       "      <th>Serial Number</th>\n",
       "      <th>FileName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03/26/06 17:58:38.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>531980</td>\n",
       "      <td>AL RRG_060403a.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03/27/06 13:23:29.5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>531980</td>\n",
       "      <td>AL RRG_060403a.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03/27/06 13:37:13.5</td>\n",
       "      <td>0.02</td>\n",
       "      <td>531980</td>\n",
       "      <td>AL RRG_060403a.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03/27/06 13:47:53.5</td>\n",
       "      <td>0.03</td>\n",
       "      <td>531980</td>\n",
       "      <td>AL RRG_060403a.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03/27/06 13:53:57.5</td>\n",
       "      <td>0.04</td>\n",
       "      <td>531980</td>\n",
       "      <td>AL RRG_060403a.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date Time  Event (Rain bucket tip) Serial Number  \\\n",
       "0  03/26/06 17:58:38.0                     0.00        531980   \n",
       "1  03/27/06 13:23:29.5                     0.01        531980   \n",
       "2  03/27/06 13:37:13.5                     0.02        531980   \n",
       "3  03/27/06 13:47:53.5                     0.03        531980   \n",
       "4  03/27/06 13:53:57.5                     0.04        531980   \n",
       "\n",
       "             FileName  \n",
       "0  AL RRG_060403a.txt  \n",
       "1  AL RRG_060403a.txt  \n",
       "2  AL RRG_060403a.txt  \n",
       "3  AL RRG_060403a.txt  \n",
       "4  AL RRG_060403a.txt  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Time</th>\n",
       "      <th>Event (Events)</th>\n",
       "      <th>Serial Number</th>\n",
       "      <th>FileName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12/15/09 16:31:03.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>AL_RRG_091222 remove first tip.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/15/09 16:31:24.0</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>None</td>\n",
       "      <td>AL_RRG_091222 remove first tip.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/16/09 09:04:57.0</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>None</td>\n",
       "      <td>AL_RRG_091222 remove first tip.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/16/09 09:20:12.5</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>None</td>\n",
       "      <td>AL_RRG_091222 remove first tip.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/16/09 09:40:41.0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>None</td>\n",
       "      <td>AL_RRG_091222 remove first tip.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date Time  Event (Events) Serial Number  \\\n",
       "0  12/15/09 16:31:03.0        0.000000          None   \n",
       "1  12/15/09 16:31:24.0        0.010870          None   \n",
       "2  12/16/09 09:04:57.0        0.021739          None   \n",
       "3  12/16/09 09:20:12.5        0.032609          None   \n",
       "4  12/16/09 09:40:41.0        0.043478          None   \n",
       "\n",
       "                             FileName  \n",
       "0  AL_RRG_091222 remove first tip.txt  \n",
       "1  AL_RRG_091222 remove first tip.txt  \n",
       "2  AL_RRG_091222 remove first tip.txt  \n",
       "3  AL_RRG_091222 remove first tip.txt  \n",
       "4  AL_RRG_091222 remove first tip.txt  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "ex_headers_csv_list = []\n",
    "\n",
    "for path in list_ex_headers:\n",
    "    csv = header_fixer(path = path)\n",
    "    csv[\"FileName\"] = path.split(sep=\"/\")[-1]\n",
    "    ex_headers_csv_list.append(csv) #create a list of test dataframes\n",
    "    display(csv.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deal with column names\n",
    "That seems to be working okay, but there are definitely some differences in column names that are going to give us issues later, so lets create a function to deal with those. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columnNames_handler(dataframe, column_names = []):\n",
    "    \"\"\"takes in a pandas dataframe, and replaces the column names with \n",
    "    the ones provided in the column_names list.  if lengths don't match, it retains \n",
    "    names exceeding the list, or discards names from the list if there are less \n",
    "    columns than the length of the list.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pandas dataframe): a pandas dataframe with a cleaned header.\n",
    "        column_names (list, optional): list of column names (string). Defaults to [].\n",
    "    \"\"\"\n",
    "    df_num_cols = len(dataframe.columns)\n",
    "\n",
    "    if len(column_names) > df_num_cols: #if there are too many column names given\n",
    "        column_names = column_names[:(df_num_cols)] \n",
    "    elif len(column_names) < df_num_cols: #if there are too few column names given\n",
    "        column_names = column_names + dataframe.columns[len(column_names):]\n",
    "    \n",
    "    dataframe.columns = column_names\n",
    "\n",
    "    return dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and a test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['DateTime', 'BucketTip_Cumm', 'Serial Number', 'FileName'], dtype='object')\n",
      "Index(['DateTime', 'BucketTip_Cumm', 'Serial Number', 'FileName'], dtype='object')\n",
      "Index(['DateTime', 'BucketTip_Cumm', 'Serial Number', 'FileName'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "\n",
    "column_names = [\"DateTime\",\"BucketTip_Cumm\",\"Serial Number\",\"FileName\"]\n",
    "for df in ex_headers_csv_list:\n",
    "    ex_headers_csv_list[index] = columnNames_handler(dataframe=df, column_names=column_names)\n",
    "    print(df.columns)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deal with cummulative values\n",
    "As you can see, individual bucket tips were summed up progressively as more tips were recorded.  This is helpful for finding the amount of total rainfall for the length of time between log pulls from precipitation monitors, but will make no sense when combined with other datasets.  There are a couple options for dealing with this:\n",
    "\n",
    "1. just make one record for each timespan between log pulls in the final dataset\n",
    "2. solve for each individual bucket tip and make them non-cummulative \n",
    "\n",
    "option 2 will allow us to preserve the data in its most granular form, so that future analyists can aggrigate the data as they see fit, so that is what we will work towards.\n",
    "https://stackoverflow.com/questions/27581942/how-can-i-get-back-real-value-from-cumulative-sum-in-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'BucketTip_Cumm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\samer\\OneDrive - Cal Poly\\Classes\\SPR_Fellowship\\SPR_Fellowship\\SPR_Fellowship_Python\\WorkingWithTxtData.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/samer/OneDrive%20-%20Cal%20Poly/Classes/SPR_Fellowship/SPR_Fellowship/SPR_Fellowship_Python/WorkingWithTxtData.ipynb#ch0000017?line=0'>1</a>\u001b[0m ex_headers_csv_list[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mBucketTip_Cumm\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m#check accumulation of values\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/samer/OneDrive%20-%20Cal%20Poly/Classes/SPR_Fellowship/SPR_Fellowship/SPR_Fellowship_Python/WorkingWithTxtData.ipynb#ch0000017?line=1'>2</a>\u001b[0m ex_headers_csv_list[\u001b[39m0\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mBucketTip_Cumm\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mBucketTip_Cumm\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n",
      "File \u001b[1;32mc:\\Users\\samer\\OneDrive - Cal Poly\\Classes\\SPR_Fellowship\\SPR_Fellowship\\SPR_Fellowship_Python\\venv\\lib\\site-packages\\pandas\\core\\series.py:958\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/samer/OneDrive%20-%20Cal%20Poly/Classes/SPR_Fellowship/SPR_Fellowship/SPR_Fellowship_Python/venv/lib/site-packages/pandas/core/series.py?line=954'>955</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[0;32m    <a href='file:///c%3A/Users/samer/OneDrive%20-%20Cal%20Poly/Classes/SPR_Fellowship/SPR_Fellowship/SPR_Fellowship_Python/venv/lib/site-packages/pandas/core/series.py?line=956'>957</a>\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> <a href='file:///c%3A/Users/samer/OneDrive%20-%20Cal%20Poly/Classes/SPR_Fellowship/SPR_Fellowship/SPR_Fellowship_Python/venv/lib/site-packages/pandas/core/series.py?line=957'>958</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[0;32m    <a href='file:///c%3A/Users/samer/OneDrive%20-%20Cal%20Poly/Classes/SPR_Fellowship/SPR_Fellowship/SPR_Fellowship_Python/venv/lib/site-packages/pandas/core/series.py?line=959'>960</a>\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    <a href='file:///c%3A/Users/samer/OneDrive%20-%20Cal%20Poly/Classes/SPR_Fellowship/SPR_Fellowship/SPR_Fellowship_Python/venv/lib/site-packages/pandas/core/series.py?line=960'>961</a>\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/samer/OneDrive%20-%20Cal%20Poly/Classes/SPR_Fellowship/SPR_Fellowship/SPR_Fellowship_Python/venv/lib/site-packages/pandas/core/series.py?line=961'>962</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/samer/OneDrive%20-%20Cal%20Poly/Classes/SPR_Fellowship/SPR_Fellowship/SPR_Fellowship_Python/venv/lib/site-packages/pandas/core/series.py?line=962'>963</a>\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\samer\\OneDrive - Cal Poly\\Classes\\SPR_Fellowship\\SPR_Fellowship\\SPR_Fellowship_Python\\venv\\lib\\site-packages\\pandas\\core\\series.py:1069\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/samer/OneDrive%20-%20Cal%20Poly/Classes/SPR_Fellowship/SPR_Fellowship/SPR_Fellowship_Python/venv/lib/site-packages/pandas/core/series.py?line=1065'>1066</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[0;32m   <a href='file:///c%3A/Users/samer/OneDrive%20-%20Cal%20Poly/Classes/SPR_Fellowship/SPR_Fellowship/SPR_Fellowship_Python/venv/lib/site-packages/pandas/core/series.py?line=1067'>1068</a>\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/samer/OneDrive%20-%20Cal%20Poly/Classes/SPR_Fellowship/SPR_Fellowship/SPR_Fellowship_Python/venv/lib/site-packages/pandas/core/series.py?line=1068'>1069</a>\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[0;32m   <a href='file:///c%3A/Users/samer/OneDrive%20-%20Cal%20Poly/Classes/SPR_Fellowship/SPR_Fellowship/SPR_Fellowship_Python/venv/lib/site-packages/pandas/core/series.py?line=1069'>1070</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32mc:\\Users\\samer\\OneDrive - Cal Poly\\Classes\\SPR_Fellowship\\SPR_Fellowship\\SPR_Fellowship_Python\\venv\\lib\\site-packages\\pandas\\core\\indexes\\range.py:389\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/samer/OneDrive%20-%20Cal%20Poly/Classes/SPR_Fellowship/SPR_Fellowship/SPR_Fellowship_Python/venv/lib/site-packages/pandas/core/indexes/range.py?line=386'>387</a>\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/samer/OneDrive%20-%20Cal%20Poly/Classes/SPR_Fellowship/SPR_Fellowship/SPR_Fellowship_Python/venv/lib/site-packages/pandas/core/indexes/range.py?line=387'>388</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m--> <a href='file:///c%3A/Users/samer/OneDrive%20-%20Cal%20Poly/Classes/SPR_Fellowship/SPR_Fellowship/SPR_Fellowship_Python/venv/lib/site-packages/pandas/core/indexes/range.py?line=388'>389</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n\u001b[0;32m    <a href='file:///c%3A/Users/samer/OneDrive%20-%20Cal%20Poly/Classes/SPR_Fellowship/SPR_Fellowship/SPR_Fellowship_Python/venv/lib/site-packages/pandas/core/indexes/range.py?line=389'>390</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mget_loc(key, method\u001b[39m=\u001b[39mmethod, tolerance\u001b[39m=\u001b[39mtolerance)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'BucketTip_Cumm'"
     ]
    }
   ],
   "source": [
    "ex_headers_csv_list[0][\"BucketTip_Cumm\"] #check accumulation of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.00\n",
       "1     0.01\n",
       "2     0.01\n",
       "3     0.01\n",
       "4     0.01\n",
       "5     0.01\n",
       "6     0.01\n",
       "7     0.01\n",
       "8     0.01\n",
       "9     0.01\n",
       "10    0.00\n",
       "Name: precip_individual, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cumm_to_individual(dataframe, column_index_or_name, indiv_column_name):\n",
    "    \"\"\"given a column with cummulative values, add a column with individual non-cummulative records\n",
    "\n",
    "    Args:\n",
    "        dataframe (pandas df): _description_\n",
    "        column_index_or_name (int or str): _description_\n",
    "        column_name (str): _description_\n",
    "    \"\"\"\n",
    "    if type(column_index_or_name) == int:\n",
    "        col = dataframe.columns[column_index_or_name]\n",
    "    else:\n",
    "        col = column_index_or_name\n",
    "    \n",
    "    dataframe[indiv_column_name] = dataframe[col].diff().fillna(dataframe[col].iloc[0])\n",
    "    return dataframe\n",
    "\n",
    "cumm_to_individual(dataframe=ex_headers_csv_list[0], column_index_or_name=\"BucketTip_Cumm\", indiv_column_name=\"precip_individual\")[\"precip_individual\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looks much better, now just iterate over all the datasets to give them all that value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combine all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "11cc95a52f21860d355b65157fedcea858f9dca3a5e33388e082c92262d6fb27"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
